- #studynotes Machine Learning for Engineers
- **Lecture 4 - Hidden Markov Models**
	- these models add transition information between the Gaussians
	- ![image.png](../assets/image_1705051176006_0.png){:height 300, :width 300}
	- transition matrix describes the probability of getting from *state i* to *state j* in one step
	- applications of HMM -- used in many fields as a tool for time series or sequence analysis, and to recover a data sequence that is not immediately observable
		- sentence completion (ie. on mobile devices)
		- data compression
		- text classification
		- automatic writing
		- speech recognition
		- ![image.png](../assets/image_1705052270678_0.png){:height 400, :width 400}
	- Intermediary variables in HMM
		- ![image.png](../assets/image_1705054087952_0.png){:height 400, :width 400}
	- Viterbi decoding
		- MAP = maximum a posteriori
		- MPE = most probable explanation
		- if you're interested in knowing the most probable sequence of states
	- HMM with dynamic features
		- good for generating new data
- **Lecture 5 - Dimensionality Reduction**
	-
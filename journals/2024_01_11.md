- #studynotes Machine Learning for Engineers
- **Lecture 1 - Introduction to Machine Learning**
	- *What is machine learning?*
		- Ex. mathematical model that gives the probability that a photo represents a face, where 0 is not a face and 1 is a face
		- aims at designing algorithms to infer the world regularities from a finite set of examples
		- in practice, given a set of training examples *D*, build automatically a predictor *f** of a hidden value given the visible signal
		- performance should be good on test data which are not available to chose the predictor
		- ![image.png](../assets/image_1704969094657_0.png){:height 500, :width 500}
	- TOPICS
		- Generative models
		  logseq.order-list-type:: number
			- directed / non-directed models
			  logseq.order-list-type:: number
			- conditional independence
			  logseq.order-list-type:: number
			- maximum likelihood and maximum a posteriori
			  logseq.order-list-type:: number
			- k-Mean + Gaussian Mixture Models (GMM) + E-M algorithm
			  logseq.order-list-type:: number
			- hidden markov models (HMM)
			  logseq.order-list-type:: number
		- Dimensionality reduction
		  logseq.order-list-type:: number
			- PCA, probabilistic PCA, T-SNE
			  logseq.order-list-type:: number
		- Regression techniques
		  logseq.order-list-type:: number
			- least-square + weighted least square
			  logseq.order-list-type:: number
			- iteratively reweighted least squares (IRLS)
			  logseq.order-list-type:: number
			- tensor factorization methods
			  logseq.order-list-type:: number
			- Gaussian mixture regression (GMR)
			  logseq.order-list-type:: number
			- Gaussian process regression (GPR)
			  logseq.order-list-type:: number
		- Classification methods
		  logseq.order-list-type:: number
			- KNN and Naive Bayes
			  logseq.order-list-type:: number
			- decision trees and ensemble methods (random forest)
			  logseq.order-list-type:: number
			- kernel methods and SVM
			  logseq.order-list-type:: number
		- Deep learning
		  logseq.order-list-type:: number
			- multilayer perceptron
			  logseq.order-list-type:: number
			- convolution neural network (CNN)
			  logseq.order-list-type:: number
			- learning methods and CNN models
			  logseq.order-list-type:: number
	- Probability
		- ![image.png](../assets/image_1704969740735_0.png){:height 500, :width 500}
	- Gradient descent
		- gradient should be 0, therefore you find the minimum of this function
		- ![image.png](../assets/image_1704970709944_0.png)
	- **Three types of learning/ predictions**
		- Classification
		  logseq.order-list-type:: number
			- ie. object recognition, cancer detection, speech processing
			  logseq.order-list-type:: number
		- Regression
		  logseq.order-list-type:: number
			- ie. customer satisfaction, stock prediction, epidemiology
			  logseq.order-list-type:: number
		- Density estimation
		  logseq.order-list-type:: number
			- ie. data visualisation, pre-processing, outlier detection
			  logseq.order-list-type:: number
	- Learning consists of finding a "good" functional in a pre-defined set of functionals *F*
	- We define "good" functionals through a loss function
	- Under/Overfitting
		- a sign of overfitting is when
		- increasing the data size reduces the effect / risk of overfitting
		- regularization - penalizing the large coefficients - also reduces overfitting
		- k-classifier AKA nearest neighbour classifier, where you predict that the class of an X is the class of the closest training example, also reduces overfitting
-
- Lecture 2 -
-
- Lecture 3 -
-
- Lecture 4 -
-
-
- Lecture 5 -
-